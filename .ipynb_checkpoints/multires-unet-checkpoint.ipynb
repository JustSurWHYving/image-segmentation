{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module loading\n",
    "from keras.src.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Conv2DTranspose\n",
    "from keras.src.layers import Concatenate, Input\n",
    "from keras.src.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal convolution block\n",
    "def conv_block(x, num_filters, kernel_size, padding=\"same\", act=True):\n",
    "    x = Conv2D(num_filters, kernel_size, padding=padding, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if act == True:\n",
    "        x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multires block with 3 skips\n",
    "def multires_block(x, num_filters, alpha=1.67):\n",
    "    W = num_filters * alpha\n",
    "\n",
    "    x0 = x\n",
    "\n",
    "    # 3 conv blocks in a multires block\n",
    "    x1 = conv_block(x0, int(W*0.167), 3)\n",
    "    x2 = conv_block(x1, int(W*0.333), 3)\n",
    "    x3 = conv_block(x2, int(W*0.5), 3)\n",
    "    xc = Concatenate()([x1, x2, x3])\n",
    "    xc = BatchNormalization()(xc)\n",
    "\n",
    "    nf = int(W*0.167) + int(W*0.333) + int(W*0.5)\n",
    "    sc = conv_block(x0, nf, 1, act=False)\n",
    "\n",
    "    x = Activation(\"relu\")(xc + sc)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip connections\n",
    "def res_path(x, num_filters, length):\n",
    "    for i in range(length):\n",
    "        x0 = x\n",
    "        x1 = conv_block(x0, num_filters, 3, act=False)\n",
    "        sc = conv_block(x0, num_filters, 1, act=False)\n",
    "        x = Activation(\"relu\")(x1 + sc)\n",
    "        x = BatchNormalization()(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downstream\n",
    "def encoder_block(x, num_filters, length):\n",
    "    x = multires_block(x, num_filters)\n",
    "    s = res_path(x, num_filters, length)\n",
    "    p = MaxPooling2D((2, 2))(x)\n",
    "    return s, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upstream\n",
    "def decoder_block(x, skip, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, 2, strides=2, padding=\"same\")(x)\n",
    "    x = Concatenate()([x, skip])\n",
    "    x = multires_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compile\n",
    "def build_multiresunet(shape):\n",
    "    \"\"\" Input \"\"\"\n",
    "    inputs = Input(shape)\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    p0 = inputs\n",
    "    s1, p1 = encoder_block(p0, 32, 4)\n",
    "    s2, p2 = encoder_block(p1, 64, 3)\n",
    "    s3, p3 = encoder_block(p2, 128, 2)\n",
    "    s4, p4 = encoder_block(p3, 256, 1)\n",
    "\n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = multires_block(p4, 512)\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s4, 256)\n",
    "    d2 = decoder_block(d1, s3, 128)\n",
    "    d3 = decoder_block(d2, s2, 64)\n",
    "    d4 = decoder_block(d3, s1, 32)\n",
    "\n",
    "    \"\"\" Output \"\"\"\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "    model = Model(inputs, outputs, name=\"multires-unet\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    shape = (256, 256, 3)\n",
    "    model = build_multiresunet(shape)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module loading for preprocessing\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to specified directories\n",
    "gtFine_dir = 'content/gtFine/'\n",
    "leftImg8bit_dir = 'content/leftImg8bit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract unique colors from ground truth labeled images and save the mappings to a JSON file\n",
    "def extract_unique_colors(gt_fine_dir, split='train'):\n",
    "\n",
    "    # initialize empty dict (stores unique colors with corresponding unique index)\n",
    "    unique_colors = {}\n",
    "    labels_dir = os.path.join(gt_fine_dir, split)\n",
    "    cities = os.listdir(labels_dir)\n",
    "\n",
    "    for city in cities:\n",
    "        city_dir = os.path.join(labels_dir, city)\n",
    "        label_files = [f for f in os.listdir(city_dir) if f.endswith('_gtFine_color.png')]\n",
    "\n",
    "        for file in label_files:\n",
    "            label_path = os.path.join(city_dir, file)\n",
    "            label_image = Image.open(label_path).convert('RGB')\n",
    "            label_array = np.array(label_image)\n",
    "            colors = np.unique(label_array.reshape(-1, label_array.shape[2]), axis=0)\n",
    "            for color in colors:\n",
    "                unique_colors[tuple(color)] = len(unique_colors)\n",
    "            print('file '+ label_path+' extracted')\n",
    "\n",
    "    # Cache the class2color and color2class mappings\n",
    "    with open('class2color.json', 'w') as f:\n",
    "        json.dump({str(k): v for k, v in unique_colors.items()}, f)\n",
    "\n",
    "    return unique_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved color-to-class mappings from 'class2color.json' and return both class-to-color and color-to-class mappings\n",
    "def load_class2color_mapping():\n",
    "    with open('class2color.json', 'r') as f:\n",
    "        class2color = json.load(f)\n",
    "    color2class = {tuple(map(int, k.strip(\"()\").split(','))): v for k, v in class2color.items()}\n",
    "    return color2class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting labeled image into a class index map using the color2class mapping\n",
    "def color_to_class(label, color2class):\n",
    "    label_class = np.zeros((label.shape[0], label.shape[1]), dtype=np.int64)\n",
    "    for color, class_idx in color2class.items():\n",
    "        mask = np.all(label == np.array(color), axis=-1)\n",
    "        label_class[mask] = class_idx\n",
    "    return label_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataset class to handle semantic segmentations\n",
    "class CityscapesDataset:\n",
    "    def __init__(self, gt_fine_dir, left_img_dir, class2color, split='train', image_size=(256, 512)):\n",
    "        self.split = split\n",
    "        self.class2color = class2color\n",
    "        self.color2class = {v: k for k, v in class2color.items()}\n",
    "        self.image_size = image_size\n",
    "        self.images_dir = os.path.join(left_img_dir, split)\n",
    "        self.labels_dir = os.path.join(gt_fine_dir, split)\n",
    "        self.cities = os.listdir(self.images_dir)\n",
    "        self.files = []\n",
    "\n",
    "        for city in self.cities:\n",
    "            img_dir = os.path.join(self.images_dir, city)\n",
    "            label_dir = os.path.join(self.labels_dir, city)\n",
    "            img_files = os.listdir(img_dir)\n",
    "\n",
    "            for file in img_files:\n",
    "                if file.endswith('_leftImg8bit.png'):\n",
    "                    img_path = os.path.join(img_dir, file)\n",
    "                    label_file = file.replace('_leftImg8bit.png', '_gtFine_color.png')\n",
    "                    label_path = os.path.join(label_dir, label_file)\n",
    "                    self.files.append((img_path, label_path))\n",
    "\n",
    "        print(f\"Found {len(self.files)} image-label pairs in the {split} split.\")\n",
    "\n",
    "    def preprocess(self, img_path, label_path):\n",
    "        # Read image and label\n",
    "        image = Image.open(img_path.numpy().decode('utf-8')).convert('RGB')\n",
    "        label = Image.open(label_path.numpy().decode('utf-8')).convert('RGB')\n",
    "\n",
    "        # Resize\n",
    "        image = image.resize(self.image_size)\n",
    "        label = label.resize(self.image_size)\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        image = np.array(image)\n",
    "        label = np.array(label)\n",
    "\n",
    "        # Normalize image\n",
    "        image = image / 255.0\n",
    "\n",
    "        # Convert label to class indices\n",
    "        label = color_to_class(label, self.color2class)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def map_func(self, img_path, label_path):\n",
    "        image, label = tf.py_function(func=self.preprocess, inp=[img_path, label_path], Tout=[tf.float32, tf.int64])\n",
    "        image.set_shape(self.image_size + (3,))\n",
    "        label.set_shape(self.image_size)\n",
    "        return image, label\n",
    "\n",
    "    def create_dataset(self, batch_size=8, shuffle=True, buffer_size=1000):\n",
    "        img_paths = [x[0] for x in self.files]\n",
    "        label_paths = [x[1] for x in self.files]\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((img_paths, label_paths))\n",
    "        dataset = dataset.map(self.map_func, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        \n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size)\n",
    "\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the colors\n",
    "extract_unique_colors(gtFine_dir)\n",
    "# Load class2color mapping\n",
    "color2class = load_class2color_mapping()\n",
    "\n",
    "# Initialize the dataset\n",
    "cityscapes_dataset = CityscapesDataset(\n",
    "    gt_fine_dir=gtFine_dir,\n",
    "    left_img_dir=leftImg8bit_dir,\n",
    "    class2color=color2class,\n",
    "    split='train',\n",
    "    image_size=(256, 512)\n",
    ")\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = cityscapes_dataset.create_dataset(batch_size=8, shuffle=True)\n",
    "\n",
    "# training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_batch(dataloader, class2color):\n",
    "    # Get a batch of training data\n",
    "    images, labels = next(iter(dataloader))\n",
    "    \n",
    "    # Convert tensors to numpy arrays\n",
    "    images = images.numpy().transpose((0, 2, 3, 1))\n",
    "    labels = labels.numpy()\n",
    "    \n",
    "    # Convert label indices back to colors\n",
    "    color2class = {v: k for k, v in class2color.items()}\n",
    "    labels_color = np.zeros((labels.shape[0], labels.shape[1], labels.shape[2], 3), dtype=np.uint8)\n",
    "    for i in range(labels.shape[0]):\n",
    "        for y in range(labels.shape[1]):\n",
    "            for x in range(labels.shape[2]):\n",
    "                labels_color[i, y, x] = color2class[labels[i, y, x]]\n",
    "    \n",
    "    # Plot images and labels\n",
    "    fig, axes = plt.subplots(2, len(images), figsize=(15, 5))\n",
    "    for i in range(len(images)):\n",
    "        axes[0, i].imshow(images[i])\n",
    "        axes[0, i].axis('off')\n",
    "        axes[0, i].set_title('Image')\n",
    "\n",
    "        axes[1, i].imshow(labels_color[i])\n",
    "        axes[1, i].axis('off')\n",
    "        axes[1, i].set_title('Label')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Visualize a batch from the dataloader\n",
    "visualize_batch(cityscapes_dataset,color2class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
