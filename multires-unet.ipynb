{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module loading\n",
    "from keras.src.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Conv2DTranspose\n",
    "from keras.src.layers import Concatenate, Input\n",
    "from keras.src.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal convolution block\n",
    "def conv_block(x, num_filters, kernel_size, padding=\"same\", act=True):\n",
    "    x = Conv2D(num_filters, kernel_size, padding=padding, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if act == True:\n",
    "        x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multires block with 3 skips\n",
    "def multires_block(x, num_filters, alpha=1.67):\n",
    "    W = num_filters * alpha\n",
    "\n",
    "    x0 = x\n",
    "\n",
    "    # 3 conv blocks in a multires block\n",
    "    x1 = conv_block(x0, int(W*0.167), 3)\n",
    "    x2 = conv_block(x1, int(W*0.333), 3)\n",
    "    x3 = conv_block(x2, int(W*0.5), 3)\n",
    "    xc = Concatenate()([x1, x2, x3])\n",
    "    xc = BatchNormalization()(xc)\n",
    "\n",
    "    nf = int(W*0.167) + int(W*0.333) + int(W*0.5)\n",
    "    sc = conv_block(x0, nf, 1, act=False)\n",
    "\n",
    "    x = Activation(\"relu\")(xc + sc)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip connections\n",
    "def res_path(x, num_filters, length):\n",
    "    for i in range(length):\n",
    "        x0 = x\n",
    "        x1 = conv_block(x0, num_filters, 3, act=False)\n",
    "        sc = conv_block(x0, num_filters, 1, act=False)\n",
    "        x = Activation(\"relu\")(x1 + sc)\n",
    "        x = BatchNormalization()(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downstream\n",
    "def encoder_block(x, num_filters, length):\n",
    "    x = multires_block(x, num_filters)\n",
    "    s = res_path(x, num_filters, length)\n",
    "    p = MaxPooling2D((2, 2))(x)\n",
    "    return s, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upstream\n",
    "def decoder_block(x, skip, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, 2, strides=2, padding=\"same\")(x)\n",
    "    x = Concatenate()([x, skip])\n",
    "    x = multires_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compile\n",
    "def build_multiresunet(shape):\n",
    "    \"\"\" Input \"\"\"\n",
    "    inputs = Input(shape)\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    p0 = inputs\n",
    "    s1, p1 = encoder_block(p0, 32, 4)\n",
    "    s2, p2 = encoder_block(p1, 64, 3)\n",
    "    s3, p3 = encoder_block(p2, 128, 2)\n",
    "    s4, p4 = encoder_block(p3, 256, 1)\n",
    "\n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = multires_block(p4, 512)\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s4, 256)\n",
    "    d2 = decoder_block(d1, s3, 128)\n",
    "    d3 = decoder_block(d2, s2, 64)\n",
    "    d4 = decoder_block(d3, s1, 32)\n",
    "\n",
    "    \"\"\" Output \"\"\"\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "    model = Model(inputs, outputs, name=\"multires-unet\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    shape = (256, 256, 3)\n",
    "    model = build_multiresunet(shape)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module loading for preprocessing\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to specified directories\n",
    "gtFine_dir = 'content/gtFine/'\n",
    "leftImg8bit_dir = 'content/leftImg8bit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract unique colors from ground truth labeled images and save the mappings to a JSON file\n",
    "def extract_unique_colors(gt_fine_dir, split='train'):\n",
    "\n",
    "    # initialize empty dict (stores unique colors with corresponding unique index)\n",
    "    unique_colors = {}\n",
    "    labels_dir = os.path.join(gt_fine_dir, split)\n",
    "    cities = os.listdir(labels_dir)\n",
    "\n",
    "    for city in cities:\n",
    "        city_dir = os.path.join(labels_dir, city)\n",
    "        label_files = [f for f in os.listdir(city_dir) if f.endswith('_gtFine_color.png')]\n",
    "\n",
    "        for file in label_files:\n",
    "            label_path = os.path.join(city_dir, file)\n",
    "            label_image = Image.open(label_path).convert('RGB')\n",
    "            label_array = np.array(label_image)\n",
    "            colors = np.unique(label_array.reshape(-1, label_array.shape[2]), axis=0)\n",
    "            for color in colors:\n",
    "                unique_colors[tuple(color)] = len(unique_colors)\n",
    "            print('file '+ label_path+' extracted')\n",
    "\n",
    "    # Cache the class2color and color2class mappings\n",
    "    with open('class2color.json', 'w') as f:\n",
    "        json.dump({str(k): v for k, v in unique_colors.items()}, f)\n",
    "\n",
    "    return unique_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved color-to-class mappings from 'class2color.json' and return both class-to-color and color-to-class mappings\n",
    "def load_class2color_mapping():\n",
    "    with open('class2color.json', 'r') as f:\n",
    "        class2color = json.load(f)\n",
    "    color2class = {tuple(map(int, k.strip(\"()\").split(','))): v for k, v in class2color.items()}\n",
    "    return color2class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting labeled image into a class index map using the color2class mapping\n",
    "def color_to_class(label, color2class):\n",
    "    label_class = np.zeros((label.shape[0], label.shape[1]), dtype=np.int64)\n",
    "    for color, class_idx in color2class.items():\n",
    "        mask = np.all(label == np.array(color), axis=-1)\n",
    "        label_class[mask] = class_idx\n",
    "    return label_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataset class to handle semantic segmentations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
