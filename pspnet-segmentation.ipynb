{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8635518,"sourceType":"datasetVersion","datasetId":5171128}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"mkdir drive/ && mkdir content/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cp -r '/kaggle/input/cityscapes/gtFine' '/kaggle/working/content/' && cp -r '/kaggle/input/cityscapes/leftImg8bit' '/kaggle/working/content/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imports\nfrom os.path import join, isdir\nfrom os import listdir, rmdir\nfrom shutil import move, rmtree, make_archive\n\nimport os\nimport cv2\nimport glob\nimport pickle\nimport numpy as np\nimport tensorflow as tf\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nfrom sklearn.cluster import KMeans\n\nfrom keras.optimizers import Adam, SGD\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Dense, Input, Dropout, Activation, Flatten, BatchNormalization, ReLU, LeakyReLU, concatenate\nfrom keras.layers import Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D, GlobalAveragePooling2D, Add\n\n# for checkpoints storage\n#from google.colab import drive\n#drive.mount('/gdrive')\n#drive_root = '/gdrive/My Drive/AIMS DTU/2024 - Summer Projects/Semantic Segmentation/'\ndrive_root = '/kaggle/working/drive'\n\nCOLAB_DIR = '/kaggle/working/content/'\nGT_DIR = COLAB_DIR + 'gtFine/'\nIMG_DIR = COLAB_DIR + 'leftImg8bit/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# collapse child directories\nfor parent in listdir(GT_DIR):\n    parent_dir = GT_DIR + parent\n    for child in listdir(parent_dir):\n        if isdir(join(parent_dir, child)):\n            keep = glob.glob(join(parent_dir, child) + '/*_gtFine_color.png')\n            keep = [f.split('/')[-1] for f in keep]\n            for filename in list(set(listdir(join(parent_dir, child))) & set(keep)):\n                move(join(parent_dir, child, filename), join(parent_dir, filename))\n            rmtree(join(parent_dir, child))\n\nfor parent in listdir(IMG_DIR):\n    parent_dir = IMG_DIR + parent\n    for child in listdir(parent_dir):\n        if isdir(join(parent_dir, child)):\n            for filename in listdir(join(parent_dir, child)):\n                move(join(parent_dir, child, filename), join(parent_dir, filename))\n            rmtree(join(parent_dir, child))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalize image pixels (z-score to impliment)\nIMG_SIZE = 256\nBATCH_SIZE = 32\nAUTOTUNE = tf.data.experimental.AUTOTUNE  # auto tunes the pipeline's performance\n\ndef load_and_preprocess_image(path):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n    img /= 256.0\n    return img\n\n\ndef get_image_paths(dir):\n#    return sorted([os.path.join(dir, path) for path in os.listdir(dir)])\n    return sorted([dir + path for path in listdir(dir)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create tf.Dataset objects\ngt_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR + 'train/'))\ngt_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR + 'val/'))\ngt_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR + 'test/'))\n\ngt_train_ds = gt_train_ds.map(load_and_preprocess_image)\ngt_val_ds = gt_val_ds.map(load_and_preprocess_image)\ngt_test_ds = gt_test_ds.map(load_and_preprocess_image)\n\nim_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR + 'train/'))\nim_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR + 'val/'))\nim_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR + 'test/'))\n\nim_train_ds = im_train_ds.map(load_and_preprocess_image)\nim_val_ds = im_val_ds.map(load_and_preprocess_image)\nim_test_ds = im_test_ds.map(load_and_preprocess_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize the data\ndef visualize_images(img, gt, pred):\n    if pred is not None:\n        fig, axes = plt.subplots(1, 3, figsize=(12, 8))\n    else:\n        fig, axes = plt.subplots(1, 2, figsize=(8, 8))\n\n    axes[0].imshow(img)\n    axes[0].set_title('Actual Image')\n\n    axes[1].imshow(gt)\n    axes[1].set_title('Masked Image')\n    \n    if pred is not None:\n        axes[2].imshow(pred)\n        axes[2].set_title('Predicted Image')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing image with corresponding mask\nfor img, gt in list(zip(im_train_ds.take(2), gt_train_ds.take(2))):\n    visualize_images(img, gt, None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resizing class\nclass ResizeLayer(tf.keras.layers.Layer):\n    def __init__(self, size, **kwargs):\n        super(ResizeLayer, self).__init__(**kwargs)\n        self.size = size\n        \n    def call(self, inputs):\n        return tf.image.resize(inputs, self.size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pspnet architecture implimentation\ndef conv_block(X, filters, block):\n    # resiudal block with dilated convolutions\n    # add skip connection at last after doing convoluion\n\n    b = 'block_' + str(block) + '_'\n    f1, f2, f3 = filters\n    X_skip = X\n\n    # block_a\n    X = Conv2D(filters=f1, kernel_size=(1, 1), dilation_rate=(1, 1),\n               padding='same', kernel_initializer='he_normal', name=b + 'a')(X)\n    X = BatchNormalization(name=b + 'batch_norm_a')(X)\n    X = LeakyReLU(alpha=0.2, name=b + 'leakyrelu_a')(X)\n    # block_b\n    X = Conv2D(filters=f2, kernel_size=(3, 3), dilation_rate=(2, 2),\n               padding='same', kernel_initializer='he_normal', name=b + 'b')(X)\n    X = BatchNormalization(name=b + 'batch_norm_b')(X)\n    X = LeakyReLU(alpha=0.2, name=b + 'leakyrelu_b')(X)\n    # block_c\n    X = Conv2D(filters=f3, kernel_size=(1, 1), dilation_rate=(1, 1),\n               padding='same', kernel_initializer='he_normal', name=b + 'c')(X)\n    X = BatchNormalization(name=b + 'batch_norm_c')(X)\n    # skip_conv\n    X_skip = Conv2D(filters=f3, kernel_size=(3, 3), padding='same', name=b + 'skip_conv')(X_skip)\n    X_skip = BatchNormalization(name=b + 'batch_norm_skip_conv')(X_skip)\n    # block_c + skip_conv\n    X = Add(name=b + 'add')([X, X_skip])\n    X = ReLU(name=b + 'relu')(X)\n    return X\n\n\ndef base_feature_maps(input_layer):\n    # base covolution module to get input image feature maps\n\n    # block_1\n    base = conv_block(input_layer, [16, 16, 32], '1')\n    # block_2\n    base = conv_block(base, [16, 16, 32], '2')\n    return base\n\n\ndef pyramid_feature_maps(input_layer):\n    # pyramid pooling module\n\n    base = base_feature_maps(input_layer)\n    # red\n    red = GlobalAveragePooling2D(name='red_pool')(base)\n    red = tf.keras.layers.Reshape((1, 1, 32))(red)\n    red = Conv2D(filters=32, kernel_size=(1, 1), name='red_1_by_1')(red)\n    red = UpSampling2D(size=128, interpolation='bilinear', name='red_upsampling')(red)\n#    red = tf.image.resize(red, [IMG_SIZE, IMG_SIZE])\n    red = ResizeLayer(size=(IMG_SIZE, IMG_SIZE))(red)\n    \n    # yellow\n    yellow = AveragePooling2D(pool_size=(2, 2), name='yellow_pool')(base)\n    yellow = Conv2D(filters=32, kernel_size=(1, 1), name='yellow_1_by_1')(yellow)\n    yellow = UpSampling2D(size=2, interpolation='bilinear', name='yellow_upsampling')(yellow)\n#    yellow = tf.image.resize(yellow, [IMG_SIZE, IMG_SIZE])\n    yellow = ResizeLayer(size=(IMG_SIZE, IMG_SIZE))(yellow)  \n    \n    # blue\n    blue = AveragePooling2D(pool_size=(4, 4), name='blue_pool')(base)\n    blue = Conv2D(filters=32, kernel_size=(1, 1), name='blue_1_by_1')(blue)\n    blue = UpSampling2D(size=4, interpolation='bilinear', name='blue_upsampling')(blue)\n#    blue = tf.image.resize(blue, [IMG_SIZE, IMG_SIZE])\n    blue = ResizeLayer(size=(IMG_SIZE, IMG_SIZE))(blue)\n    \n    # green\n    green = AveragePooling2D(pool_size=(8, 8), name='green_pool')(base)\n    green = Conv2D(filters=32, kernel_size=(1, 1), name='green_1_by_1')(green)\n    green = UpSampling2D(size=8, interpolation='bilinear', name='green_upsampling')(green)\n#    green = tf.image.resize(green, [IMG_SIZE, IMG_SIZE])\n    green = ResizeLayer(size=(IMG_SIZE, IMG_SIZE))(green)\n    \n    \n    # base + red + yellow + blue + green\n    base = ResizeLayer(size=(IMG_SIZE, IMG_SIZE))(base)\n    return tf.keras.layers.concatenate([base, red, yellow, blue, green])\n\n\ndef last_conv_module(input_layer):\n    X = pyramid_feature_maps(input_layer)\n    X = Conv2D(filters=3, kernel_size=3, padding='same', name='last_conv_3_by_3')(X)\n    X = BatchNormalization(name='last_conv_3_by_3_batch_norm')(X)\n    X = Activation('sigmoid', name='last_conv_relu')(X)\n    return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = list(im_train_ds.take(1))[0].shape\ninput_layer = tf.keras.Input(shape=input_shape, name='input')\noutput_layer = last_conv_module(input_layer)\n\nmodel = tf.keras.Model(inputs=input_layer, outputs=output_layer)\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training & Evaluation","metadata":{}},{"cell_type":"code","source":"train_ds = tf.data.Dataset.zip((im_train_ds, gt_train_ds))\ntrain_ds = train_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\nval_ds = tf.data.Dataset.zip((im_val_ds, gt_val_ds))\nval_ds = val_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\ntest_ds = tf.data.Dataset.zip((im_test_ds, gt_test_ds))\ntest_ds = test_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = drive_root+'pspnet/cp.ckpt'\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)\nes_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n\nmodel.compile(optimizer='adam', loss='mse', metrics='accuracy')\nhistory = model.fit(train_ds, validation_data=val_ds, epochs=5, \n                    callbacks=[cp_callback, es_callback])\nmodel.save(drive_root + 'pspnet_trained.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train and val accuracy and loss vs epochs\ndef plot(history):\n  acc = history.history['accuracy']\n  val_acc = history.history['val_accuracy']\n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  epochs = range(1,len(acc)+1)\n\n  plt.title('Training and validation accuracy')\n  plt.plot(epochs, acc, color='blue', label='Train')\n  plt.plot(epochs, val_acc, color='orange', label='Val')\n  plt.xlabel('Epoch')\n  plt.ylabel('Accuracy')\n  plt.legend()\n\n  _ = plt.figure()\n  plt.title('Training and validation loss')\n  plt.plot(epochs, loss, color='blue', label='Train')\n  plt.plot(epochs, val_loss, color='orange', label='Val')\n  plt.xlabel('Epoch')\n  plt.ylabel('Loss')\n  plt.legend()\n  \nplot(history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}