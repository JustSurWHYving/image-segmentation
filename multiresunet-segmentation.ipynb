{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8635518,"sourceType":"datasetVersion","datasetId":5171128}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Initial Setup","metadata":{}},{"cell_type":"code","source":"mkdir drive/ && mkdir content/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cp -r '/kaggle/input/gtFine' '/kaggle/working/content/' && cp -r '/kaggle/input/leftImg8bit' '/kaggle/working/content/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imports\nfrom os.path import join, isdir\nfrom os import listdir, rmdir\nfrom shutil import move, rmtree, make_archive\n\nimport os\nimport cv2\nimport glob\nimport pickle\nimport numpy as np\nimport tensorflow as tf\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nfrom sklearn.cluster import KMeans\n\nfrom keras.optimizers import Adam, SGD\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Dense, Input, Dropout, Activation, Flatten, BatchNormalization, ReLU, LeakyReLU, concatenate\nfrom keras.layers import Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D, GlobalAveragePooling2D, Add\n\n# for checkpoints storage\n#from google.colab import drive\n#drive.mount('/gdrive')\n#drive_root = '/gdrive/My Drive/AIMS DTU/2024 - Summer Projects/Semantic Segmentation/'\ndrive_root = '/kaggle/working/drive'\n\nCOLAB_DIR = '/kaggle/working/content/'\nGT_DIR = COLAB_DIR + 'gtFine/'\nIMG_DIR = COLAB_DIR + 'leftImg8bit/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# collapse child directories\nfor parent in listdir(GT_DIR):\n    parent_dir = GT_DIR + parent\n    for child in listdir(parent_dir):\n        if isdir(join(parent_dir, child)):\n            keep = glob.glob(join(parent_dir, child) + '/*_gtFine_color.png')\n            keep = [f.split('/')[-1] for f in keep]\n            for filename in list(set(listdir(join(parent_dir, child))) & set(keep)):\n                move(join(parent_dir, child, filename), join(parent_dir, filename))\n            rmtree(join(parent_dir, child))\n\nfor parent in listdir(IMG_DIR):\n    parent_dir = IMG_DIR + parent\n    for child in listdir(parent_dir):\n        if isdir(join(parent_dir, child)):\n            for filename in listdir(join(parent_dir, child)):\n                move(join(parent_dir, child, filename), join(parent_dir, filename))\n            rmtree(join(parent_dir, child))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"# normalize image pixels (z-score to impliment)\nIMG_SIZE = 256\nBATCH_SIZE = 32\nAUTOTUNE = tf.data.experimental.AUTOTUNE  # auto tunes the pipeline's performance\n\ndef load_and_preprocess_image(path):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n    img /= 256.0\n    return img\n\n\ndef get_image_paths(dir):\n#    return sorted([os.path.join(dir, path) for path in os.listdir(dir)])\n    return sorted([dir + path for path in listdir(dir)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create tf.Dataset objects\ngt_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR + 'train/'))\ngt_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR + 'val/'))\ngt_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR + 'test/'))\n\ngt_train_ds = gt_train_ds.map(load_and_preprocess_image)\ngt_val_ds = gt_val_ds.map(load_and_preprocess_image)\ngt_test_ds = gt_test_ds.map(load_and_preprocess_image)\n\nim_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR + 'train/'))\nim_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR + 'val/'))\nim_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR + 'test/'))\n\nim_train_ds = im_train_ds.map(load_and_preprocess_image)\nim_val_ds = im_val_ds.map(load_and_preprocess_image)\nim_test_ds = im_test_ds.map(load_and_preprocess_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize the data\ndef visualize_images(img, gt, pred):\n    if pred is not None:\n        fig, axes = plt.subplots(1, 3, figsize=(12, 8))\n    else:\n        fig, axes = plt.subplots(1, 2, figsize=(8, 8))\n\n    axes[0].imshow(img)\n    axes[0].set_title('Actual Image')\n\n    axes[1].imshow(gt)\n    axes[1].set_title('Masked Image')\n    \n    if pred is not None:\n        axes[2].imshow(pred)\n        axes[2].set_title('Predicted Image')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing image with corresponding mask\nfor img, gt in list(zip(im_train_ds.take(2), gt_train_ds.take(2))):\n    visualize_images(img, gt, None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Architecture","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Conv2DTranspose\nfrom tensorflow.keras.layers import Concatenate, Input\nfrom tensorflow.keras.models import Model\n\ndef conv_block(x, num_filters, kernel_size, padding=\"same\", act=True):\n    x = Conv2D(num_filters, kernel_size, padding=padding, use_bias=False)(x)\n    x = BatchNormalization()(x)\n    if act:\n        x = Activation(\"relu\")(x)\n    return x\n\ndef multires_block(x, num_filters, alpha=1.67):\n    W = num_filters * alpha\n\n    x0 = x\n    x1 = conv_block(x0, int(W*0.167), 3)\n    x2 = conv_block(x1, int(W*0.333), 3)\n    x3 = conv_block(x2, int(W*0.5), 3)\n    xc = Concatenate()([x1, x2, x3])\n    xc = BatchNormalization()(xc)\n\n    nf = int(W*0.167) + int(W*0.333) + int(W*0.5)\n    sc = conv_block(x0, nf, 1, act=False)\n\n    x = Activation(\"relu\")(xc + sc)\n    x = BatchNormalization()(x)\n    return x\n\ndef res_path(x, num_filters, length):\n    for i in range(length):\n        x0 = x\n        x1 = conv_block(x0, num_filters, 3, act=False)\n        sc = conv_block(x0, num_filters, 1, act=False)\n        x = Activation(\"relu\")(x1 + sc)\n        x = BatchNormalization()(x)\n    return x\n\ndef encoder_block(x, num_filters, length):\n    x = multires_block(x, num_filters)\n    s = res_path(x, num_filters, length)\n    p = MaxPooling2D((2, 2))(x)\n    return s, p\n\ndef decoder_block(x, skip, num_filters):\n    x = Conv2DTranspose(num_filters, 2, strides=2, padding=\"same\")(x)\n    x = Concatenate()([x, skip])\n    x = multires_block(x, num_filters)\n    return x\n\ndef build_multiresunet(input_layer):\n    \"\"\" Input \"\"\"\n    inputs = input_layer\n\n    \"\"\" Encoder \"\"\"\n    p0 = inputs\n    s1, p1 = encoder_block(p0, 32, 4)\n    s2, p2 = encoder_block(p1, 64, 3)\n    s3, p3 = encoder_block(p2, 128, 2)\n    s4, p4 = encoder_block(p3, 256, 1)\n\n    \"\"\" Bridge \"\"\"\n    b1 = multires_block(p4, 512)\n\n    \"\"\" Decoder \"\"\"\n    d1 = decoder_block(b1, s4, 256)\n    d2 = decoder_block(d1, s3, 128)\n    d3 = decoder_block(d2, s2, 64)\n    d4 = decoder_block(d3, s1, 32)\n\n    \"\"\" Output \"\"\"\n    #outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n    outputs = d4\n    return d4\n    \n\ndef last_conv_module(input_layer):\n    x = build_multiresunet(input_layer)\n    x = Conv2D(filters=1,kernel_size=1,padding='same',name='last_conv_1_by_1')(x)\n    #x = BatchNormalization(name='last_conv_1_by_1_batch_norm')(x)\n    x = Activation('sigmoid',name='last_conv_sigmoid')(x)\n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = list(im_train_ds.take(1))[0].shape\ninput_layer = tf.keras.Input(shape=input_shape, name='input')\noutput_layer = last_conv_module(input_layer)\n\nmodel = tf.keras.Model(inputs=input_layer, outputs=output_layer, name=\"MultiResUNET\")\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training & Evaluation","metadata":{}},{"cell_type":"code","source":"train_ds = tf.data.Dataset.zip((im_train_ds, gt_train_ds))\ntrain_ds = train_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\nval_ds = tf.data.Dataset.zip((im_val_ds, gt_val_ds))\nval_ds = val_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\ntest_ds = tf.data.Dataset.zip((im_test_ds, gt_test_ds))\ntest_ds = test_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = drive_root+'multiresunet.weights.h5'\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)\nes_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n\nmodel.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\nhistory = model.fit(train_ds, validation_data=val_ds, epochs=5, \n                    callbacks=[cp_callback, es_callback])\nmodel.save(drive_root + 'multiresunet_trained.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train and val accuracy and loss vs epochs\ndef plot(history):\n  acc = history.history['accuracy']\n  val_acc = history.history['val_accuracy']\n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  epochs = range(1,len(acc)+1)\n\n  plt.title('Training and validation accuracy')\n  plt.plot(epochs, acc, color='blue', label='Train')\n  plt.plot(epochs, val_acc, color='orange', label='Val')\n  plt.xlabel('Epoch')\n  plt.ylabel('Accuracy')\n  plt.legend()\n\n  _ = plt.figure()\n  plt.title('Training and validation loss')\n  plt.plot(epochs, loss, color='blue', label='Train')\n  plt.plot(epochs, val_loss, color='orange', label='Val')\n  plt.xlabel('Epoch')\n  plt.ylabel('Loss')\n  plt.legend()\n  \nplot(history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, acc = model.evaluate(test_ds)\nprint('Test Data Accuracy: ', acc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing Predictions","metadata":{}},{"cell_type":"code","source":"pred_test_ds = model.predict(train_ds)\n\nfor img, gt, pred in list(zip(im_train_ds.take(5), gt_train_ds.take(5), pred_test_ds)):\n    visualize_images(img, gt, pred)","metadata":{},"execution_count":null,"outputs":[]}]}