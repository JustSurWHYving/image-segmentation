{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848827cd-2164-43a1-8b9b-d9c956ba10e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os.path import join, isdir\n",
    "from os import listdir, rmdir\n",
    "from shutil import move, rmtree, make_archive\n",
    "from PIL import Image\n",
    "from keras.src.models.model import Model\n",
    "from keras.src.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d21b7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "DRIVE_DIR = 'drive/'\n",
    "CONTENT_DIR = 'content/'\n",
    "GT_DIR = CONTENT_DIR + 'gtFine/'\n",
    "IMG_DIR = CONTENT_DIR + 'leftImg8bit/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse child directories\n",
    "for parent in listdir(GT_DIR):\n",
    "    parent_dir = GT_DIR + parent\n",
    "    for child in listdir(parent_dir):\n",
    "        if isdir(join(parent_dir, child)):\n",
    "            keep = glob.glob(join(parent_dir, child) + '/*_gtFine_color.png')\n",
    "            keep = [f.split('/')[-1] for f in keep]\n",
    "            for filename in list(set(listdir(join(parent_dir, child))) & set(keep)):\n",
    "                move(join(parent_dir, child, filename), join(parent_dir, filename))\n",
    "            rmtree(join(parent_dir, child))\n",
    "\n",
    "for parent in listdir(IMG_DIR):\n",
    "    parent_dir = IMG_DIR + parent\n",
    "    for child in listdir(parent_dir):\n",
    "        if isdir(join(parent_dir, child)):\n",
    "            for filename in listdir(join(parent_dir, child)):\n",
    "                move(join(parent_dir, child, filename), join(parent_dir, filename))\n",
    "            rmtree(join(parent_dir, child))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad32a3b-4be7-4e74-b51a-b4adc5b5219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize image pixels (z-score to impliment)\n",
    "IMG_SIZE = 299\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE  # auto tunes the pipeline's performance\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
    "    img /= 255.0\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_image_paths(dir):\n",
    "#    return sorted([os.path.join(dir, path) for path in os.listdir(dir)])\n",
    "    return sorted([dir + path for path in listdir(dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e5cd74-2584-47fe-8cea-518f5771d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tf.Dataset objects\n",
    "gt_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR + 'train/'))\n",
    "gt_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR + 'val/'))\n",
    "gt_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(GT_DIR + 'test/'))\n",
    "\n",
    "gt_train_ds = gt_train_ds.map(load_and_preprocess_image)\n",
    "gt_val_ds = gt_val_ds.map(load_and_preprocess_image)\n",
    "gt_test_ds = gt_test_ds.map(load_and_preprocess_image)\n",
    "\n",
    "im_train_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR + 'train/'))\n",
    "im_val_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR + 'val/'))\n",
    "im_test_ds = tf.data.Dataset.from_tensor_slices(get_image_paths(IMG_DIR + 'test/'))\n",
    "\n",
    "im_train_ds = im_train_ds.map(load_and_preprocess_image)\n",
    "im_val_ds = im_val_ds.map(load_and_preprocess_image)\n",
    "im_test_ds = im_test_ds.map(load_and_preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe92ce-fecd-4427-8d94-eec3c14aa4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pspnet architecture implimentation\n",
    "def conv_block(X, filters, block):\n",
    "    # resiudal block with dilated convolutions\n",
    "    # add skip connection at last after doing convoluion\n",
    "\n",
    "    b = 'block_' + str(block) + '_'\n",
    "    f1, f2, f3 = filters\n",
    "    X_skip = X\n",
    "\n",
    "    # block_a\n",
    "    X = Conv2D(filters=f1, kernel_size=(1, 1), dilation_rate=(1, 1),\n",
    "               padding='same', kernel_initializer='he_normal', name=b + 'a')(X)\n",
    "    X = BatchNormalization(name=b + 'batch_norm_a')(X)\n",
    "    X = LeakyReLU(alpha=0.2, name=b + 'leakyrelu_a')(X)\n",
    "    # block_b\n",
    "    X = Conv2D(filters=f2, kernel_size=(3, 3), dilation_rate=(2, 2),\n",
    "               padding='same', kernel_initializer='he_normal', name=b + 'b')(X)\n",
    "    X = BatchNormalization(name=b + 'batch_norm_b')(X)\n",
    "    X = LeakyReLU(alpha=0.2, name=b + 'leakyrelu_b')(X)\n",
    "    # block_c\n",
    "    X = Conv2D(filters=f3, kernel_size=(1, 1), dilation_rate=(1, 1),\n",
    "               padding='same', kernel_initializer='he_normal', name=b + 'c')(X)\n",
    "    X = BatchNormalization(name=b + 'batch_norm_c')(X)\n",
    "    # skip_conv\n",
    "    X_skip = Conv2D(filters=f3, kernel_size=(3, 3), padding='same', name=b + 'skip_conv')(X_skip)\n",
    "    X_skip = BatchNormalization(name=b + 'batch_norm_skip_conv')(X_skip)\n",
    "    # block_c + skip_conv\n",
    "    X = Add(name=b + 'add')([X, X_skip])\n",
    "    X = ReLU(name=b + 'relu')(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "def base_feature_maps(input_layer):\n",
    "    # base covolution module to get input image feature maps\n",
    "\n",
    "    # block_1\n",
    "    base = conv_block(input_layer, [16, 16, 32], '1')\n",
    "    # block_2\n",
    "    base = conv_block(base, [16, 16, 32], '2')\n",
    "    return base\n",
    "\n",
    "\n",
    "def pyramid_feature_maps(input_layer):\n",
    "    # pyramid pooling module\n",
    "\n",
    "    base = base_feature_maps(input_layer)\n",
    "    # red\n",
    "    red = GlobalAveragePooling2D(name='red_pool')(base)\n",
    "    red = tf.keras.layers.Reshape((1, 1, 32))(red)\n",
    "    red = Conv2D(filters=32, kernel_size=(1, 1), name='red_1_by_1')(red)\n",
    "    red = UpSampling2D(size=128, interpolation='bilinear', name='red_upsampling')(red)\n",
    "    red = tf.image.resize(red, [IMG_SIZE, IMG_SIZE])\n",
    "    # yellow\n",
    "    yellow = AveragePooling2D(pool_size=(2, 2), name='yellow_pool')(base)\n",
    "    yellow = Conv2D(filters=32, kernel_size=(1, 1), name='yellow_1_by_1')(yellow)\n",
    "    yellow = UpSampling2D(size=2, interpolation='bilinear', name='yellow_upsampling')(yellow)\n",
    "    yellow = tf.image.resize(yellow, [IMG_SIZE, IMG_SIZE])\n",
    "    # blue\n",
    "    blue = AveragePooling2D(pool_size=(4, 4), name='blue_pool')(base)\n",
    "    blue = Conv2D(filters=32, kernel_size=(1, 1), name='blue_1_by_1')(blue)\n",
    "    blue = UpSampling2D(size=4, interpolation='bilinear', name='blue_upsampling')(blue)\n",
    "    blue = tf.image.resize(blue, [IMG_SIZE, IMG_SIZE])\n",
    "    # green\n",
    "    green = AveragePooling2D(pool_size=(8, 8), name='green_pool')(base)\n",
    "    green = Conv2D(filters=32, kernel_size=(1, 1), name='green_1_by_1')(green)\n",
    "    green = UpSampling2D(size=8, interpolation='bilinear', name='green_upsampling')(green)\n",
    "    green = tf.image.resize(green, [IMG_SIZE, IMG_SIZE])\n",
    "    # base + red + yellow + blue + green\n",
    "    return tf.keras.layers.concatenate([base, red, yellow, blue, green])\n",
    "\n",
    "\n",
    "def last_conv_module(input_layer):\n",
    "    X = pyramid_feature_maps(input_layer)\n",
    "    X = Conv2D(filters=3, kernel_size=3, padding='same', name='last_conv_3_by_3')(X)\n",
    "    X = BatchNormalization(name='last_conv_3_by_3_batch_norm')(X)\n",
    "    X = Activation('sigmoid', name='last_conv_relu')(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329147ec-6d6c-4bcb-84bf-ff3e630cb532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input and output layer dims & define\n",
    "input_shape = list(im_train_ds.take((1)))[0].shape\n",
    "input_layer = Input(shape=input_shape, name='input')\n",
    "output_layer = last_conv_module(input_layer)\n",
    "\n",
    "# model compile\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "print(model.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de52109-f9db-4db1-89e6-955e6e916072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
